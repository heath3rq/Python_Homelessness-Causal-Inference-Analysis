{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import COC Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CoC Code</th>\n",
       "      <th>Coc</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>FIPS code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ-502</td>\n",
       "      <td>Phoenix,Mesa/Maricopa</td>\n",
       "      <td>Maricopa County</td>\n",
       "      <td>4013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>CA-600</td>\n",
       "      <td>Los Angeles City &amp; County</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>6037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>CA-601</td>\n",
       "      <td>San Diego City and County</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>6073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>CA-500</td>\n",
       "      <td>San Jose/Santa Clara City &amp; County</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>6085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>CA-609</td>\n",
       "      <td>San Bernardino City &amp; County</td>\n",
       "      <td>San Bernardino County</td>\n",
       "      <td>6071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State      STNAME CoC Code                                 Coc  \\\n",
       "0    AZ     Arizona   AZ-502               Phoenix,Mesa/Maricopa   \n",
       "1    CA  California   CA-600           Los Angeles City & County   \n",
       "2    CA  California   CA-601           San Diego City and County   \n",
       "3    CA  California   CA-500  San Jose/Santa Clara City & County   \n",
       "4    CA  California   CA-609        San Bernardino City & County   \n",
       "\n",
       "                 CTYNAME  FIPS code  \n",
       "0        Maricopa County       4013  \n",
       "1     Los Angeles County       6037  \n",
       "2       San Diego County       6073  \n",
       "3     Santa Clara County       6085  \n",
       "4  San Bernardino County       6071  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coc_mapping = pd.read_csv(\n",
    "    \"/Users/lorna/Documents/MIDS 2022/Spring 2023/Unifying DS/final project uds/src/unifying-data-science-2023-project-team3/00_source_data/COC mapping.csv\"\n",
    ")\n",
    "coc_mapping.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "States = coc_mapping[\"STNAME\"].unique()\n",
    "cols = [\n",
    "    \"STATE\",\n",
    "    \"COUNTY\",\n",
    "    \"STNAME\",\n",
    "    \"CTYNAME\",\n",
    "    \"YEAR\",\n",
    "    \"AGEGRP\",\n",
    "    \"TOT_POP\",\n",
    "    \"TOT_MALE\",\n",
    "    \"TOT_FEMALE\",\n",
    "    \"WA_MALE\",\n",
    "    \"WA_FEMALE\",\n",
    "    \"BA_MALE\",\n",
    "    \"BA_FEMALE\",\n",
    "    \"IA_MALE\",\n",
    "    \"IA_FEMALE\",\n",
    "    \"AA_MALE\",\n",
    "    \"AA_FEMALE\",\n",
    "    \"NA_MALE\",\n",
    "    \"NA_FEMALE\",\n",
    "    \"TOM_MALE\",\n",
    "    \"TOM_FEMALE\",\n",
    "    \"NH_MALE\",\n",
    "    \"NH_FEMALE\",\n",
    "    \"H_MALE\",\n",
    "    \"H_FEMALE\",\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import 2007 to 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_07_10_subset = []\n",
    "missing_files = [3, 7, 14, 43, 52]\n",
    "chunk_size = 5000\n",
    "for i in range(1, 57):\n",
    "    if i in missing_files:\n",
    "        continue\n",
    "    if i < 10:\n",
    "        i = f\"0{i}\"\n",
    "        url = f\"https://www2.census.gov/programs-surveys/popest/datasets/2000-2010/intercensal/county/co-est00int-alldata-{i}.csv\"\n",
    "    else:\n",
    "        url = f\"https://www2.census.gov/programs-surveys/popest/datasets/2000-2010/intercensal/county/co-est00int-alldata-{i}.csv\"\n",
    "    pop_07_10_raw = pd.read_csv(url, encoding=\"ISO-8859-1\", usecols=cols)\n",
    "    pop_07_10_filtered = pop_07_10_raw[\n",
    "        (pop_07_10_raw[\"YEAR\"].isin([9, 10, 11, 13]))\n",
    "        & (pop_07_10_raw[\"STNAME\"].isin(States))\n",
    "        & (pop_07_10_raw[\"AGEGRP\"] == 0)\n",
    "    ]\n",
    "    pop_07_10_subset.append(pop_07_10_filtered)\n",
    "\n",
    "pop_07_10 = pd.concat(pop_07_10_subset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import 2011 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5000\n",
    "url = \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/asrh/CC-EST2020-ALLDATA.csv\"\n",
    "pop_11_20_raw = pd.read_csv(\n",
    "    url, encoding=\"ISO-8859-1\", chunksize=chunk_size, usecols=cols\n",
    ")\n",
    "pop_11_20_filtered = []\n",
    "years = [i for i in range(4, 14)]\n",
    "# Iterate over the chunks\n",
    "for data in pop_11_20_raw:\n",
    "    tmp = data[\n",
    "        (data[\"YEAR\"].isin(years))\n",
    "        & (data[\"STNAME\"].isin(States))\n",
    "        & (data[\"AGEGRP\"] == 0)\n",
    "    ]\n",
    "    pop_11_20_filtered.append(tmp)\n",
    "\n",
    "pop_11_20 = pd.concat(pop_11_20_filtered)\n",
    "# pop_11_20.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www2.census.gov/programs-surveys/popest/datasets/2020-2021/counties/asrh/cc-est2021-all.csv\"\n",
    "pop_21_raw = pd.read_csv(url, encoding=\"ISO-8859-1\", usecols=cols)\n",
    "pop_21 = pop_21_raw[\n",
    "    (pop_21_raw[\"YEAR\"] == 3)\n",
    "    & pop_21_raw[\"STNAME\"].isin(States)\n",
    "    & (pop_21_raw[\"AGEGRP\"] == 0)\n",
    "].copy()\n",
    "# pop_21.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 30)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge all data sets with coc mapping\n",
    "pop_07_10_merged = pd.merge(\n",
    "    coc_mapping,\n",
    "    pop_07_10,\n",
    "    left_on=[\"STNAME\", \"CTYNAME\"],\n",
    "    right_on=[\"STNAME\", \"CTYNAME\"],\n",
    "    how=\"left\",\n",
    "    indicator=True,\n",
    ")\n",
    "pop_07_10_merged.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 30)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_11_20_merged = pd.merge(\n",
    "    coc_mapping,\n",
    "    pop_11_20,\n",
    "    left_on=[\"STNAME\", \"CTYNAME\"],\n",
    "    right_on=[\"STNAME\", \"CTYNAME\"],\n",
    "    how=\"left\",\n",
    "    indicator=True,\n",
    ")\n",
    "pop_11_20_merged.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 30)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_21_merged = pd.merge(\n",
    "    coc_mapping,\n",
    "    pop_21,\n",
    "    left_on=[\"STNAME\", \"CTYNAME\"],\n",
    "    right_on=[\"STNAME\", \"CTYNAME\"],\n",
    "    how=\"left\",\n",
    "    indicator=True,\n",
    ")\n",
    "pop_21_merged.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "### Clean Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found\n",
      "0 Nans found\n",
      "No duplicates found\n",
      "0 Nans found\n",
      "No duplicates found\n",
      "0 Nans found\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "def check_dups(data):\n",
    "    \"\"\"checks duplicates and NANs\"\"\"\n",
    "    # check duplicates\n",
    "    dups = data[data.duplicated()]\n",
    "    if len(dups) >= 1:\n",
    "        print(f\"duplicates found in {pop}\")\n",
    "        data_no_dups = data.drop_duplicates().reset_index(drop=True)\n",
    "        print(f\"- {len(dups)} duplicate(s) deleted\")\n",
    "    else:\n",
    "        print(\"No duplicates found\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_Na(data):\n",
    "    \"checks for NAs\"\n",
    "    data_nas = data.isnull().sum().sum()\n",
    "    print(f\"{data_nas} Nans found\")\n",
    "    return None\n",
    "\n",
    "\n",
    "for pop in [pop_07_10_merged, pop_11_20_merged, pop_21_merged]:\n",
    "    check_dups(pop)\n",
    "    check_Na(pop)\n",
    "# Check for NAs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_add = [\n",
    "    \"WA_MALE\",\n",
    "    \"WA_FEMALE\",\n",
    "    \"BA_MALE\",\n",
    "    \"BA_FEMALE\",\n",
    "    \"IA_MALE\",\n",
    "    \"IA_FEMALE\",\n",
    "    \"AA_MALE\",\n",
    "    \"AA_FEMALE\",\n",
    "    \"NA_MALE\",\n",
    "    \"NA_FEMALE\",\n",
    "    \"TOM_MALE\",\n",
    "    \"TOM_FEMALE\",\n",
    "    \"NH_MALE\",\n",
    "    \"NH_FEMALE\",\n",
    "    \"H_MALE\",\n",
    "    \"H_FEMALE\",\n",
    "]\n",
    "\n",
    "# slide over the cols to add and them up\n",
    "def create_totals(data):\n",
    "    i = 0\n",
    "    while i < (len(cols_to_add) - 1):\n",
    "        col1 = cols_to_add[i]\n",
    "        col2 = cols_to_add[i + 1]\n",
    "        col_name = col1[:2]\n",
    "        data[f\"{col_name}_TOTAL\"] = data[col1] + data[col2]\n",
    "        i += 2\n",
    "    return data\n",
    "\n",
    "\n",
    "pop_07_10_totaled = create_totals(pop_07_10_merged)\n",
    "pop_11_20_totaled = create_totals(pop_11_20_merged)\n",
    "pop_21_totaled = create_totals(pop_21_merged)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007    31\n",
       "2008    31\n",
       "2009    31\n",
       "2010    31\n",
       "Name: New_YEAR, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (pop_07_10_totaled[\"YEAR\"] == 9),\n",
    "    (pop_07_10_totaled[\"YEAR\"] == 10),\n",
    "    (pop_07_10_totaled[\"YEAR\"] == 11),\n",
    "    (pop_07_10_totaled[\"YEAR\"] == 13),\n",
    "]\n",
    "\n",
    "values = [2007, 2008, 2009, 2010]\n",
    "\n",
    "pop_07_10_totaled[\"New_YEAR\"] = np.select(conditions, values)\n",
    "pop_07_10_totaled[\"New_YEAR\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011    31\n",
       "2012    31\n",
       "2013    31\n",
       "2014    31\n",
       "2015    31\n",
       "2016    31\n",
       "2017    31\n",
       "2018    31\n",
       "2019    31\n",
       "2020    31\n",
       "Name: New_YEAR, dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 4),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 5),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 6),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 7),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 8),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 9),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 10),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 11),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 12),\n",
    "    (pop_11_20_totaled[\"YEAR\"] == 13),\n",
    "]\n",
    "\n",
    "values = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "pop_11_20_totaled[\"New_YEAR\"] = np.select(conditions, values)\n",
    "pop_11_20_totaled[\"New_YEAR\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021    31\n",
       "Name: New_YEAR, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [(pop_21_totaled[\"YEAR\"] == 3)]\n",
    "values = [2021]\n",
    "\n",
    "pop_21_totaled[\"New_YEAR\"] = np.select(conditions, values)\n",
    "pop_21_totaled[\"New_YEAR\"].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for totals only.\n",
    "cols_to_subset = [\n",
    "    \"STNAME\",\n",
    "    \"CoC Code\",\n",
    "    \"Coc\",\n",
    "    \"FIPS code\",\n",
    "    \"CTYNAME\",\n",
    "    \"New_YEAR\",\n",
    "    \"TOT_POP\",\n",
    "    \"TOT_MALE\",\n",
    "    \"TOT_FEMALE\",\n",
    "    \"WA_TOTAL\",\n",
    "    \"BA_TOTAL\",\n",
    "    \"IA_TOTAL\",\n",
    "    \"AA_TOTAL\",\n",
    "    \"NA_TOTAL\",\n",
    "    \"TO_TOTAL\",\n",
    "    \"NH_TOTAL\",\n",
    "    \"H__TOTAL\",\n",
    "]\n",
    "\n",
    "\n",
    "pop_07_10_final = pop_07_10_totaled[cols_to_subset].copy()\n",
    "pop_11_20_final = pop_11_20_totaled[cols_to_subset].copy()\n",
    "pop_21_final = pop_21_totaled[cols_to_subset].copy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = {\"New_YEAR\": \"Year\",\n",
    "            \"TOT_POP\": \"Population\",\n",
    "            \"TOT_MALE\": \"Male\",\n",
    "            \"TOT_FEMALE\": \"Female\",\n",
    "            \"WA_TOTAL\": \"White\",\n",
    "            \"BA_TOTAL\": \"Black or African American\",\n",
    "            \"IA_TOTAL\": \"American Indian and Alaska Native\",\n",
    "            \"AA_TOTAL\": \"Asian\",\n",
    "            \"NA_TOTAL\": \"Native Hawaiian and Other Pacific Islander\",\n",
    "            \"TO_TOTAL\": \"Two or More Races\",\n",
    "            \"NH_TOTAL\": \"Non Hispanic\",\n",
    "            \"H__TOTAL\": \"Hispanic\"}\n",
    "population_by_race = pd.concat([pop_07_10_final, pop_11_20_final, pop_21_final],ignore_index=True)\n",
    "population_by_race = population_by_race.rename(columns=col_name).sort_values(by = [\"CTYNAME\", \"Year\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛑 check write path\n",
    "population_by_race.to_csv(\"20_intermediate_files/population_race.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4de7276074beb09e94c04d5e134c141d0f336e3226759f4865dc0d0ce3d2e27e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
